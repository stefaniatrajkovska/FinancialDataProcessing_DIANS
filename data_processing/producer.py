from confluent_kafka import Producer
import pandas as pd
import json
import time
import logging
import socket

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# Kafka Configuration
KAFKA_BROKER = "localhost:9092"
KAFKA_TOPIC = "historical_financial_data"
INPUT_CSV_PATH = ("../data_scraping/stock_data.csv")  # CSV file generated by scraping_data.py


def delivery_report(err, msg):
    """Callback function for message delivery reports"""
    if err is not None:
        print(f"Message delivery failed: {err}")
    else:
        print(f"Message delivered to {msg.topic()} [{msg.partition()}] at offset {msg.offset()}")


def create_kafka_producer():
    """Create and return a Confluent Kafka producer instance"""
    try:
        conf = {
            'bootstrap.servers': KAFKA_BROKER,
            'client.id': socket.gethostname()
        }
        producer = Producer(conf)
        print("Confluent Kafka producer created successfully")
        return producer
    except Exception as e:
        print(f"Error creating Confluent Kafka producer: {e}")
        return None


def send_data_to_kafka(producer, topic, data):
    """Send data to Kafka topic using Confluent Kafka"""
    try:
        json_data = json.dumps(data)
        key = str(data['Symbol'])

        # Logging before sending data
        print(f"Sending data to Kafka for symbol: {data['Symbol']}")

        producer.produce(
            topic=topic,
            key=key.encode('utf-8'),
            value=json_data.encode('utf-8'),
            callback=delivery_report
        )
        producer.poll(0)

        return True
    except Exception as e:
        print(f"Error sending data to Kafka: {e}")
        return False


def process_stock_data():
    """Process the CSV file to get correctly formatted stock data"""
    try:
        # Read the CSV file with first row as header
        df = pd.read_csv(INPUT_CSV_PATH)

        # Get the actual stock data (skipping the header row mess)
        result_data = []

        for index, row in df.iterrows():
            if pd.notna(row['Symbol']):  # Only process rows with a valid Symbol
                stock_data = {
                    'Symbol': row['Symbol'],
                    'Date': row['Date'],
                    'Open': float(row['Open']) if pd.notna(row['Open']) else None,
                    'High': float(row['High']) if pd.notna(row['High']) else None,
                    'Low': float(row['Low']) if pd.notna(row['Low']) else None,
                    'Close': float(row['Close']) if pd.notna(row['Close']) else None,
                    'Volume': float(row['Volume']) if pd.notna(row['Volume']) else None
                }
                result_data.append(stock_data)

        return result_data
    except Exception as e:
        print(f"Error processing stock data: {e}")
        return []


def main():
    # Create Kafka producer
    producer = create_kafka_producer()
    if not producer:
        return

    try:
        # Process the stock data properly
        stock_data = process_stock_data()

        if not stock_data:
            print("No valid stock data found")
            return

        print(f"Processed {len(stock_data)} valid stock records")

        # Counter for successful sends
        sent_count = 0

        print("Starting data streaming...")
        # Process only once - no infinite loop
        for index, data in enumerate(stock_data):
            # Send to Kafka
            if send_data_to_kafka(producer, KAFKA_TOPIC, data):
                sent_count += 1

            # Add delay between messages
            time.sleep(0.1)

            # Log progress periodically
            if index % 10 == 0:
                print(f"Processed {index} records")
                # Flush to ensure messages are delivered
                producer.flush()

        # Log after complete iteration
        print(f"Completed sending {sent_count} messages to Kafka")

    except KeyboardInterrupt:
        print("Producer stopped by user")
    except Exception as e:
        print(f"Error in main process: {e}")
        import traceback
        print(traceback.format_exc())  # Print full stack trace
    finally:
        # Flush and close producer
        if producer:
            producer.flush()
            print("Kafka producer flushed and closed")


if __name__ == "__main__":
    main()
